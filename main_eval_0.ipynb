{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aad53baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0e30d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import socket\n",
    "import time\n",
    "import random\n",
    "import glob\n",
    "import argparse, json\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dedef115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/users/eleves-a/2020/abdellah.el-mrini/graphtransformer'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86c93128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nets.SBMs_node_classification.graph_transformer_net import GraphTransformerNet\n",
    "from train.train_SBMs_node_classification import evaluate_network\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9176e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.data import LoadData \n",
    "from nets.SBMs_node_classification.load_net import gnn_model \n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f00dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = 'configs/SBMs_GraphTransformer_LapPE_CLUSTER_500k_sparse_graph_LN.json'\n",
    "\n",
    "with open(config_file, 'r') as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c73a5a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_params = config['net_params']\n",
    "net_params['in_dim']= 7\n",
    "net_params['n_classes'] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d26abced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_setup(use_gpu, gpu_id):\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)  \n",
    "\n",
    "    if torch.cuda.is_available() and use_gpu:\n",
    "        print('cuda available with GPU:',torch.cuda.get_device_name(0))\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        print('cuda not available')\n",
    "        device = torch.device(\"cpu\")\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b45b14e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available with GPU: Quadro P2200\n"
     ]
    }
   ],
   "source": [
    "device = gpu_setup(config['gpu']['use'], config['gpu']['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33942a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_params['device'] = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1762597a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphTransformerNet(net_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a58849e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7f2a9e57e1d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9db4f3f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('out/ModelsParams/epoch_82.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "133a554d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphTransformerNet(\n",
       "  (embedding_lap_pos_enc): Linear(in_features=10, out_features=80, bias=True)\n",
       "  (embedding_h): Embedding(7, 80)\n",
       "  (in_feat_dropout): Dropout(p=0.0, inplace=False)\n",
       "  (layers): ModuleList(\n",
       "    (0): GraphTransformerLayer(in_channels=80, out_channels=80, heads=8, residual=True)\n",
       "    (1): GraphTransformerLayer(in_channels=80, out_channels=80, heads=8, residual=True)\n",
       "    (2): GraphTransformerLayer(in_channels=80, out_channels=80, heads=8, residual=True)\n",
       "    (3): GraphTransformerLayer(in_channels=80, out_channels=80, heads=8, residual=True)\n",
       "    (4): GraphTransformerLayer(in_channels=80, out_channels=80, heads=8, residual=True)\n",
       "    (5): GraphTransformerLayer(in_channels=80, out_channels=80, heads=8, residual=True)\n",
       "    (6): GraphTransformerLayer(in_channels=80, out_channels=80, heads=8, residual=True)\n",
       "    (7): GraphTransformerLayer(in_channels=80, out_channels=80, heads=8, residual=True)\n",
       "    (8): GraphTransformerLayer(in_channels=80, out_channels=80, heads=8, residual=True)\n",
       "    (9): GraphTransformerLayer(in_channels=80, out_channels=80, heads=8, residual=True)\n",
       "  )\n",
       "  (MLP_layer): MLPReadout(\n",
       "    (FC_layers): ModuleList(\n",
       "      (0): Linear(in_features=80, out_features=40, bias=True)\n",
       "      (1): Linear(in_features=40, out_features=20, bias=True)\n",
       "      (2): Linear(in_features=20, out_features=6, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc71814c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_model_param(MODEL_NAME, net_params):\n",
    "    model = gnn_model(MODEL_NAME, net_params)\n",
    "    total_param = 0\n",
    "    print(\"MODEL DETAILS:\\n\")\n",
    "    #print(model)\n",
    "    for param in model.parameters():\n",
    "        # print(param.data.size())\n",
    "        total_param += np.prod(list(param.data.size()))\n",
    "    print('MODEL/Total parameters:', MODEL_NAME, total_param)\n",
    "    return total_param\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7afc810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_pipeline(MODEL_NAME, dataset, params, net_params, dirs):\n",
    "    \n",
    "    start0 = time.time()\n",
    "    per_epoch_time = []\n",
    "    \n",
    "    DATASET_NAME = dataset.name\n",
    "    \n",
    "    if net_params['lap_pos_enc']:\n",
    "        st = time.time()\n",
    "        print(\"[!] Adding Laplacian positional encoding.\")\n",
    "        dataset._add_laplacian_positional_encodings(net_params['pos_enc_dim'])\n",
    "        print('Time LapPE:',time.time()-st)\n",
    "        \n",
    "    if net_params['wl_pos_enc']:\n",
    "        st = time.time()\n",
    "        print(\"[!] Adding WL positional encoding.\")\n",
    "        dataset._add_wl_positional_encodings()\n",
    "        print('Time WL PE:',time.time()-st)\n",
    "    \n",
    "    if net_params['full_graph']:\n",
    "        st = time.time()\n",
    "        print(\"[!] Converting the given graphs to full graphs..\")\n",
    "        dataset._make_full_graph()\n",
    "        print('Time taken to convert to full graphs:',time.time()-st)\n",
    "        \n",
    "    trainset, valset, testset = dataset.train, dataset.val, dataset.test\n",
    "        \n",
    "    root_log_dir, root_ckpt_dir, write_file_name, write_config_file = dirs\n",
    "    device = net_params['device']\n",
    "    \n",
    "    # Write network and optimization hyper-parameters in folder config/\n",
    "    with open(write_config_file + '.txt', 'w') as f:\n",
    "        f.write(\"\"\"Dataset: {},\\nModel: {}\\n\\nparams={}\\n\\nnet_params={}\\n\\n\\nTotal Parameters: {}\\n\\n\"\"\"                .format(DATASET_NAME, MODEL_NAME, params, net_params, net_params['total_param']))\n",
    "        \n",
    "    log_dir = os.path.join(root_log_dir, \"RUN_\" + str(0))\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "    # setting seeds\n",
    "    random.seed(params['seed'])\n",
    "    np.random.seed(params['seed'])\n",
    "    torch.manual_seed(params['seed'])\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.manual_seed(params['seed'])\n",
    "    \n",
    "    print(\"Training Graphs: \", len(trainset))\n",
    "    print(\"Validation Graphs: \", len(valset))\n",
    "    print(\"Test Graphs: \", len(testset))\n",
    "    print(\"Number of Classes: \", net_params['n_classes'])\n",
    "\n",
    "    model = gnn_model(MODEL_NAME, net_params)\n",
    "    model = model.to(device)\n",
    "\n",
    "    model.load_state_dict(torch.load('out/ModelsParams/epoch_82.pkl'))\n",
    "    \n",
    "    epoch_train_losses, epoch_val_losses = [], []\n",
    "    epoch_train_accs, epoch_val_accs = [], [] \n",
    "    \n",
    "    # import train and evaluate functions\n",
    "    from train.train_SBMs_node_classification import evaluate_network \n",
    "\n",
    "    train_loader = DataLoader(trainset, batch_size=params['batch_size'], shuffle=True, collate_fn=dataset.collate)\n",
    "    val_loader = DataLoader(valset, batch_size=params['batch_size'], shuffle=False, collate_fn=dataset.collate)\n",
    "    test_loader = DataLoader(testset, batch_size=params['batch_size'], shuffle=False, collate_fn=dataset.collate)\n",
    "        \n",
    "    # At any point you can hit Ctrl + C to break out of training early.\n",
    "    try:\n",
    "        with tqdm(range(params['epochs'])) as t:\n",
    "            for epoch in t:\n",
    "\n",
    "                t.set_description('Epoch %d' % epoch)\n",
    "\n",
    "                start = time.time()\n",
    "\n",
    "                epoch_train_loss, epoch_train_acc = evaluate_network(model, device, train_loader, epoch)\n",
    "                    \n",
    "                epoch_val_loss, epoch_val_acc = evaluate_network(model, device, val_loader, epoch)\n",
    "                _, epoch_test_acc = evaluate_network(model, device, test_loader, epoch)        \n",
    "                \n",
    "                epoch_train_losses.append(epoch_train_loss)\n",
    "                epoch_val_losses.append(epoch_val_loss)\n",
    "                epoch_train_accs.append(epoch_train_acc)\n",
    "                epoch_val_accs.append(epoch_val_acc)\n",
    "\n",
    "                writer.add_scalar('train/_loss', epoch_train_loss, epoch)\n",
    "                writer.add_scalar('val/_loss', epoch_val_loss, epoch)\n",
    "                writer.add_scalar('train/_acc', epoch_train_acc, epoch)\n",
    "                writer.add_scalar('val/_acc', epoch_val_acc, epoch)\n",
    "                writer.add_scalar('test/_acc', epoch_test_acc, epoch)\n",
    "\n",
    "                \n",
    "\n",
    "                per_epoch_time.append(time.time()-start)\n",
    "\n",
    "                # Saving checkpoint\n",
    "                ckpt_dir = os.path.join(root_ckpt_dir, \"RUN_\")\n",
    "                if not os.path.exists(ckpt_dir):\n",
    "                    os.makedirs(ckpt_dir)\n",
    "                torch.save(model.state_dict(), '{}.pkl'.format(ckpt_dir + \"/epoch_\" + str(epoch)))\n",
    "\n",
    "                files = glob.glob(ckpt_dir + '/*.pkl')\n",
    "                for file in files:\n",
    "                    epoch_nb = file.split('_')[-1]\n",
    "                    epoch_nb = int(epoch_nb.split('.')[0])\n",
    "                    if epoch_nb < epoch-1:\n",
    "                        os.remove(file)\n",
    "\n",
    "                    \n",
    "                # Stop training after params['max_time'] hours\n",
    "                if time.time()-start0 > params['max_time']*3600:\n",
    "                    print('-' * 89)\n",
    "                    print(\"Max_time for training elapsed {:.2f} hours, so stopping\".format(params['max_time']))\n",
    "                    break\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print('-' * 89)\n",
    "        print('Exiting from training early because of KeyboardInterrupt')\n",
    "    \n",
    "    \n",
    "    _, test_acc = evaluate_network(model, device, test_loader, epoch)\n",
    "    _, train_acc = evaluate_network(model, device, train_loader, epoch)\n",
    "    print(\"Test Accuracy: {:.4f}\".format(test_acc))\n",
    "    print(\"Train Accuracy: {:.4f}\".format(train_acc))\n",
    "    print(\"Convergence Time (Epochs): {:.4f}\".format(epoch))\n",
    "    print(\"TOTAL TIME TAKEN: {:.4f}s\".format(time.time()-start0))\n",
    "    print(\"AVG TIME PER EPOCH: {:.4f}s\".format(np.mean(per_epoch_time)))\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "    \"\"\"\n",
    "        Write the results in out_dir/results folder\n",
    "    \"\"\"\n",
    "    if not os.path.exists(write_file_name):\n",
    "        os.makedirs(write_file_name)\n",
    "    with open(write_file_name + '.txt', 'w') as f:\n",
    "        f.write(\"\"\"Dataset: {},\\nModel: {}\\n\\nparams={}\\n\\nnet_params={}\\n\\n{}\\n\\nTotal Parameters: {}\\n\\n\n",
    "    FINAL RESULTS\\nTEST ACCURACY: {:.4f}\\nTRAIN ACCURACY: {:.4f}\\n\\n\n",
    "    Convergence Time (Epochs): {:.4f}\\nTotal Time Taken: {:.4f} hrs\\nAverage Time Per Epoch: {:.4f} s\\n\\n\\n\"\"\"\\\n",
    "          .format(DATASET_NAME, MODEL_NAME, params, net_params, model, net_params['total_param'],\n",
    "                  test_acc, train_acc, epoch, (time.time()-start0)/3600, np.mean(per_epoch_time)))\n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0fd6e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotDict(dict):\n",
    "    def __init__(self, **kwds):\n",
    "        self.update(kwds)\n",
    "        self.__dict__ = self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e8a9bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] Loading dataset SBM_CLUSTER...\n",
      "train, test, val sizes : 1 1000 1\n",
      "[I] Finished loading.\n",
      "[I] Data load time: 0.5012s\n"
     ]
    }
   ],
   "source": [
    "params = config['params']\n",
    "net_params[\"batch_size\"] = params['batch_size']\n",
    "DATASET_NAME = config['dataset']\n",
    "dataset = LoadData(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3eb36ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = config['out_dir']\n",
    "MODEL_NAME =  config['model']\n",
    "root_log_dir = out_dir + 'logs/' + MODEL_NAME + \"_\" + DATASET_NAME + \"_GPU\" + str(config['gpu']['id']) + \"_\" + time.strftime('%Hh%Mm%Ss_on_%b_%d_%Y')\n",
    "root_ckpt_dir = out_dir + 'checkpoints/' + MODEL_NAME + \"_\" + DATASET_NAME + \"_GPU\" + str(config['gpu']['id']) + \"_\" + time.strftime('%Hh%Mm%Ss_on_%b_%d_%Y')\n",
    "write_file_name = out_dir + 'results/result_' + MODEL_NAME + \"_\" + DATASET_NAME + \"_GPU\" + str(config['gpu']['id']) + \"_\" + time.strftime('%Hh%Mm%Ss_on_%b_%d_%Y')\n",
    "write_config_file = out_dir + 'configs/config_' + MODEL_NAME + \"_\" + DATASET_NAME + \"_GPU\" + str(config['gpu']['id']) + \"_\" + time.strftime('%Hh%Mm%Ss_on_%b_%d_%Y')\n",
    "if not os.path.exists(out_dir + 'results'):\n",
    "    os.makedirs(out_dir + 'results')\n",
    "dirs = root_log_dir, root_ckpt_dir, write_file_name, write_config_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5675de2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params[\"epochs\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7a1ae51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<data.SBMs.load_SBMsDataSetDGL at 0x7f2a9e504e50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cbd0e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL DETAILS:\n",
      "\n",
      "MODEL/Total parameters: GraphTransformer 524026\n"
     ]
    }
   ],
   "source": [
    "net_params['total_param'] = view_model_param(MODEL_NAME, net_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c347d6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Adding Laplacian positional encoding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-a/2020/abdellah.el-mrini/miniconda3/envs/graph_transformer/lib/python3.7/site-packages/dgl/base.py:45: DGLWarning: DGLGraph.adjacency_matrix_scipy is deprecated. Please replace it with:\n",
      "\n",
      "\tDGLGraph.adjacency_matrix(transpose, scipy_fmt=\"csr\").\n",
      "\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time LapPE: 3.369917392730713\n",
      "Training Graphs:  1\n",
      "Validation Graphs:  1\n",
      "Test Graphs:  1000\n",
      "Number of Classes:  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-a/2020/abdellah.el-mrini/graphtransformer/nets/SBMs_node_classification/graph_transformer_net.py:82: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629427478/work/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  label_count = label_count[label_count.nonzero()].squeeze()\n",
      "Epoch 0: 100%|██████████| 1/1 [00:07<00:00,  7.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 19.3180\n",
      "Train Accuracy: 19.4812\n",
      "Convergence Time (Epochs): 0.0000\n",
      "TOTAL TIME TAKEN: 18.2441s\n",
      "AVG TIME PER EPOCH: 7.6739s\n"
     ]
    }
   ],
   "source": [
    "eval_pipeline(MODEL_NAME, dataset, params, net_params, dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "628c9de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(out_dir + 'results'):\n",
    "    os.makedirs(out_dir + 'results')\n",
    "        \n",
    "if not os.path.exists(out_dir + 'configs'):\n",
    "    os.makedirs(out_dir + 'configs')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8609f4f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/users/eleves-a/2020/abdellah.el-mrini/graphtransformer'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a154eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'out/SBMs_sparse_LapPE_LN/configs/config_GraphTransformer_SBM_CLUSTER_GPU0_13h22m24s_on_Mar_07_2022'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_config_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf52e36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
