{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76ea1a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import numpy as np\n",
    "import os\n",
    "import socket\n",
    "import time\n",
    "import random\n",
    "import glob\n",
    "import argparse, json\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "from nets.SBMs_node_classification.graph_transformer_net import GraphTransformerNet\n",
    "from train.train_SBMs_node_classification import evaluate_network\n",
    "import json\n",
    "from data.data import LoadData \n",
    "from nets.SBMs_node_classification.load_net import gnn_model \n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15cdbed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = 'configs/SBMs_GraphTransformer_LapPE_CLUSTER_500k_sparse_graph_BN.json'\n",
    "with open(config_file, 'r') as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88d6c988",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_params = config['net_params']\n",
    "net_params['in_dim']= 7\n",
    "net_params['n_classes'] = 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c33cfd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_setup(use_gpu, gpu_id):\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)  \n",
    "\n",
    "    if torch.cuda.is_available() and use_gpu:\n",
    "        print('cuda available with GPU:',torch.cuda.get_device_name(0))\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        print('cuda not available')\n",
    "        device = torch.device(\"cpu\")\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6ce73ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available with GPU: Quadro P2200\n"
     ]
    }
   ],
   "source": [
    "device = gpu_setup(config['gpu']['use'], config['gpu']['id'])\n",
    "net_params['device'] = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "000a0b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_model_param(MODEL_NAME, net_params):\n",
    "    model = gnn_model(MODEL_NAME, net_params)\n",
    "    total_param = 0\n",
    "    print(\"MODEL DETAILS:\\n\")\n",
    "    #print(model)\n",
    "    for param in model.parameters():\n",
    "        # print(param.data.size())\n",
    "        total_param += np.prod(list(param.data.size()))\n",
    "    print('MODEL/Total parameters:', MODEL_NAME, total_param)\n",
    "    return total_param\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19b186e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_pipeline(MODEL_NAME, dataset, params, net_params, dirs):\n",
    "    \n",
    "    start0 = time.time()\n",
    "    per_epoch_time = []\n",
    "    \n",
    "    DATASET_NAME = dataset.name\n",
    "    \n",
    "    if net_params['lap_pos_enc']:\n",
    "        st = time.time()\n",
    "        print(\"[!] Adding Laplacian positional encoding.\")\n",
    "        dataset._add_laplacian_positional_encodings(net_params['pos_enc_dim'])\n",
    "        print('Time LapPE:',time.time()-st)\n",
    "        \n",
    "    if net_params['wl_pos_enc']:\n",
    "        st = time.time()\n",
    "        print(\"[!] Adding WL positional encoding.\")\n",
    "        dataset._add_wl_positional_encodings()\n",
    "        print('Time WL PE:',time.time()-st)\n",
    "    \n",
    "    if net_params['full_graph']:\n",
    "        st = time.time()\n",
    "        print(\"[!] Converting the given graphs to full graphs..\")\n",
    "        dataset._make_full_graph()\n",
    "        print('Time taken to convert to full graphs:',time.time()-st)\n",
    "        \n",
    "    trainset, valset, testset = dataset.train, dataset.val, dataset.test\n",
    "        \n",
    "    root_log_dir, root_ckpt_dir, write_file_name, write_config_file = dirs\n",
    "    device = net_params['device']\n",
    "    \n",
    "    # Write network and optimization hyper-parameters in folder config/\n",
    "    \n",
    "    with open(write_config_file + '.txt', 'w') as f:\n",
    "        f.write(\"\"\"Dataset: {},\\nModel: {}\\n\\nparams={}\\n\\nnet_params={}\\n\\n\\nTotal Parameters: {}\\n\\n\"\"\"                .format(DATASET_NAME, MODEL_NAME, params, net_params, net_params['total_param']))\n",
    "        \n",
    "    log_dir = os.path.join(root_log_dir, \"RUN_\" + str(0))\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "    # setting seeds\n",
    "    random.seed(params['seed'])\n",
    "    np.random.seed(params['seed'])\n",
    "    torch.manual_seed(params['seed'])\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.manual_seed(params['seed'])\n",
    "    \n",
    "    print(\"Test Graphs: \", len(testset))\n",
    "    print(\"Number of Classes: \", net_params['n_classes'])\n",
    "\n",
    "    model = gnn_model(MODEL_NAME, net_params)\n",
    "    model = model.to(device)\n",
    "\n",
    "    model.load_state_dict(torch.load('out/ModelsParams/epoch_113.pkl'))\n",
    "    model.eval()\n",
    "    \n",
    "    # import train and evaluate functions\n",
    "    from train.train_SBMs_node_classification import evaluate_network \n",
    "    \n",
    "    test_loader = DataLoader(testset, batch_size=params['batch_size'], shuffle=False, collate_fn=dataset.collate)   \n",
    "    _, test_acc = evaluate_network(model, device, test_loader, epoch=1)\n",
    "    print(\"Test Accuracy: {:.4f}\".format(test_acc))\n",
    "    print(\"TOTAL TIME TAKEN: {:.4f}s\".format(time.time()-start0))\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "    \"\"\"\n",
    "        Write the results in out_dir/results folder\n",
    "    \"\"\"\n",
    "   \n",
    "    with open(write_file_name + '.txt', 'w') as f:\n",
    "        f.write(\"\"\"Dataset: {},\\nModel: {}\\n\\nparams={}\\n\\nnet_params={}\\n\\n{}\\n\\nTotal Parameters: {}\\n\\n\n",
    "    FINAL RESULTS\\nTEST ACCURACY: {:.4f}\\n\\n\n",
    "    Total Time Taken: {:.4f} hrs\\n\\n\\n\"\"\"\\\n",
    "          .format(DATASET_NAME, MODEL_NAME, params, net_params, model, net_params['total_param'],\n",
    "                  test_acc, (time.time()-start0)/3600,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a08ccff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotDict(dict):\n",
    "    def __init__(self, **kwds):\n",
    "        self.update(kwds)\n",
    "        self.__dict__ = self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30646129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] Loading dataset SBM_CLUSTER...\n",
      "train, test, val sizes : 1 1000 1\n",
      "[I] Finished loading.\n",
      "[I] Data load time: 0.4710s\n"
     ]
    }
   ],
   "source": [
    "params = config['params']\n",
    "net_params[\"batch_size\"] = params['batch_size']\n",
    "DATASET_NAME = config['dataset']\n",
    "dataset = LoadData(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01f91a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = config['out_dir']\n",
    "MODEL_NAME =  config['model']\n",
    "root_log_dir = out_dir + 'logs/' + MODEL_NAME + \"_\" + DATASET_NAME + \"_GPU\" + str(config['gpu']['id']) + \"_\" + time.strftime('%Hh%Mm%Ss_on_%b_%d_%Y')\n",
    "root_ckpt_dir = out_dir + 'checkpoints/' + MODEL_NAME + \"_\" + DATASET_NAME + \"_GPU\" + str(config['gpu']['id']) + \"_\" + time.strftime('%Hh%Mm%Ss_on_%b_%d_%Y')\n",
    "write_file_name = out_dir + 'results/result_' + MODEL_NAME + \"_\" + DATASET_NAME + \"_GPU\" + str(config['gpu']['id']) + \"_\" + time.strftime('%Hh%Mm%Ss_on_%b_%d_%Y')\n",
    "write_config_file = out_dir + 'configs/config_' + MODEL_NAME + \"_\" + DATASET_NAME + \"_GPU\" + str(config['gpu']['id']) + \"_\" + time.strftime('%Hh%Mm%Ss_on_%b_%d_%Y')\n",
    "if not os.path.exists(out_dir + 'results'):\n",
    "    os.makedirs(out_dir + 'results')\n",
    "if not os.path.exists(out_dir + 'results'):\n",
    "    os.makedirs(out_dir + 'logs')\n",
    "if not os.path.exists(out_dir + 'checkpoints'):\n",
    "    os.makedirs(out_dir + 'checkpoints')\n",
    "if not os.path.exists(out_dir + 'configs'):\n",
    "    os.makedirs(out_dir + 'configs')\n",
    "dirs = root_log_dir, root_ckpt_dir, write_file_name, write_config_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d4d0e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL DETAILS:\n",
      "\n",
      "MODEL/Total parameters: GraphTransformer 524026\n"
     ]
    }
   ],
   "source": [
    "net_params['total_param'] = view_model_param(MODEL_NAME, net_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f6ccac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Adding Laplacian positional encoding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-a/2020/abdellah.el-mrini/miniconda3/envs/graph_transformer/lib/python3.7/site-packages/dgl/base.py:45: DGLWarning: DGLGraph.adjacency_matrix_scipy is deprecated. Please replace it with:\n",
      "\n",
      "\tDGLGraph.adjacency_matrix(transpose, scipy_fmt=\"csr\").\n",
      "\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time LapPE: 3.3063464164733887\n",
      "Test Graphs:  1000\n",
      "Number of Classes:  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-a/2020/abdellah.el-mrini/graphtransformer/nets/SBMs_node_classification/graph_transformer_net.py:82: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629427478/work/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  label_count = label_count[label_count.nonzero()].squeeze()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 72.4095\n",
      "TOTAL TIME TAKEN: 10.1843s\n"
     ]
    }
   ],
   "source": [
    "eval_pipeline(MODEL_NAME, dataset, params, net_params, dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e534625b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
